---
title: "Lexical Decision Task Analysis"
output:
  pdf_document: default
  html_document: default
date: "2023-02-05"
---

# Load libraries

Note that I've loaded relevant libraries and create a merged dataframe of all Pavlovia responses and Qualtrics data.

```{r, include = FALSE}
# Load required packages
library(plotly)
library(psych)
library(r2mlm)
library(rockchalk)
library(stringr)
library(fs)
library(ggplot2)
library(lme4)
library(wesanderson)
library(tidyverse)
library(lmerTest)
library(rstatix)
```

```{r, include = FALSE}
# Set working directory to folder containing "data" folder
setwd("/Users/christinahuber/Desktop/ldt_v2 copy")
```

```{r, include = FALSE}
# Get list of .csv files in "data" folder
file_list <- dir_ls("data", regexp = "\\.csv$")

# Read in each file and bind them together
data <- map_dfr(file_list, read_csv, .id = "participant")

# Get participant number
data$participant <- str_remove(data$participant, "^data/")
data$participant <- str_remove(data$participant, "\\.csv")
```

```{r, include = FALSE}
# Remove rows without values in "on_time.keys" or "on_time_2.keys"
data <- data %>% filter(!is.na(on_time.keys) & !is.na(on_time_2.keys))

# Remove brackets and quotation marks from relevant columns
data <- data %>% mutate_all(~str_replace_all(., "[\\[\\]\"]", ""))

data <- data %>%
  mutate(good_on_left = ifelse(as.integer(str_sub(participant, -1)) %% 2 == 0, 1, 0))

# # Create "good_on_left" column
# data <- data %>% mutate(good_on_left = as.numeric(as.logical(as.integer(str_sub(participant, -1)) %% 2)))

# Create "choice_1" and "choice_2" columns
data <- data %>% 
  mutate(
    choice_1 = if_else(good_on_left == 1 & on_time.keys == "a", 1, 
                       if_else(good_on_left == 1 & on_time.keys == "l", 0, 
                               if_else(good_on_left == 0 & on_time.keys == "a", 0, 
                                       if_else(good_on_left == 0 & on_time.keys == "l", 1, NA_real_)))),
    choice_2 = if_else(good_on_left == 1 & on_time_2.keys == "a", 1, 
                       if_else(good_on_left == 1 & on_time_2.keys == "l", 0, 
                               if_else(good_on_left == 0 & on_time_2.keys == "a", 0, 
                                       if_else(good_on_left == 0 & on_time_2.keys == "l", 1, NA_real_)))))

head(data$choice_1)

# Change "yes" to 1 and "no" to 0 in correct_answer_1 and correct_answer_2
data <- data %>% 
  mutate(correct_answer_1 = if_else(correct_answer_1 == "yes", 1, 0),
         correct_answer_2 = if_else(correct_answer_2 == "yes", 1, 0))

# Convert reaction time data to numeric
data$on_time.rt <- as.numeric(data$on_time.rt)
data$on_time_2.rt <- as.numeric(data$on_time_2.rt)
```

```{r}
# data$image_condition <- ifelse(grepl("alt", data$base_image), "mismatch", "match")
```

```{r}
# Assuming df is your data frame with the column 'condition'
# First, create the new columns by splitting the 'condition' column
data <- data %>%
  mutate(
    image_condition = substr(target_condition, 1, 1),  # Extracts the first character
    target_condition = substr(target_condition, 2, 2)   # Extracts the second character
  )

# Next, recode 'image_condition' values
data$image_condition <- ifelse(data$image_condition == "I", "ctl", 
                             ifelse(data$image_condition == "D", "exper", data$image_condition))

# If you want to remove the original 'condition' column, you can use select() function
# df <- df %>% select(-condition)

# Print the updated dataframe to see the changes
print(data)
```


```{r}
# # Separate the "condition" column into "image_condition" and "word_condition"
# data <- data %>%
#   separate(target_condition, into = c("image_condition", "target_condition"), sep = "")
# 
# # Recode "image_condition" values: "I" to "ctl", "D" to "exper"
# data <- data %>%
#   mutate(image_condition = case_when(
#     image_condition == "I" ~ "ctl",
#     image_condition == "D" ~ "exper",
#     TRUE ~ image_condition # Keep original value if it's neither "I" nor "D"
#   ))

```




```{r, include = FALSE}
# Create "filtered_columns" data frame with only the relevant columns
filtered_columns <- data %>% dplyr::select(
  participant, base_image, base_word, target_word, image_condition, target_condition, 
  on_time.rt, on_time_2.rt, choice_1, choice_2, correct_answer_1, 
  correct_answer_2, run_num, early_keys.keys)

filtered_columns <- as.data.frame(filtered_columns)

filtered_columns <- filtered_columns %>%
  filter(is.na(early_keys.keys))

filtered_columns <- filtered_columns %>%
  filter(!is.na(on_time_2.rt))

filtered_columns <- filtered_columns %>%
  filter(!is.na(on_time.rt))
```

```{r exclude responses, include = FALSE}
# Motor movements take 1/5 of a second minimum
# Reactions slower than 2s were computer errors
filtered_columns <- filtered_columns %>%
  filter(on_time.rt >= 0.2 & on_time.rt <= 2 &
           on_time_2.rt >= 0.2 & on_time_2.rt <= 2)
```

```{r, include = FALSE}
# Read in the "qualtrics.csv" file
qualtrics <- read.csv("/Users/christinahuber/Desktop/ldt_v2 copy/qualtrics.csv")

filtered_columns$participant <- as.numeric(filtered_columns$participant)

qualtrics$Pavlovia.PID <- as.integer(qualtrics$Pavlovia.PID)

# Merge "data" and "qualtrics" dataframes based on the "participant" and "id" columns
filtered_columns <- inner_join(
  filtered_columns, qualtrics, by = c("participant" = "Pavlovia.PID"))

table(filtered_columns$D1)

filtered_columns <- filtered_columns %>% filter(D1 %in% c(1)) # only analyze responses of participants to who reported remaining attentive

```

```{r, include = FALSE}
# # Individual difference naive realism measures
# filtered_columns$NR1_1 <- as.numeric(filtered_columns$NR1_1)
# filtered_columns$NR1_2 <- as.numeric(filtered_columns$NR1_2) 
# 
# # Reverse-code NR1_1
# filtered_columns$NR1_1_reverse <- 8 - filtered_columns$NR1_1
# 
# # Create a composite measure
# filtered_columns$NR_composite <- filtered_columns$NR1_1_reverse + filtered_columns$NR1_2
```

```{r}
# compute trial by trial difference scores
filtered_columns <- filtered_columns %>%
  mutate(difference_rt = on_time.rt - on_time_2.rt)
``` 

```{r}
# filtered_columns$target_condition <- gsub("nw", "c", filtered_columns$target_condition)

```


```{r}
# filtered_columns$condition <- filtered_columns$target_condition

# filtered_columns <- filtered_columns %>%
#   separate(target_condition, into = c("code1", "code2"), sep = 1)

# # Create the "first_RT_mean" column
# filtered_columns <- filtered_columns %>%
#   group_by(code1, image_condition) %>%
#   mutate(first_RT_mean = mean(on_time.rt)) %>%
#   ungroup()
# 
# # Create the "first_RT_mean" column
# filtered_columns <- filtered_columns %>%
#   group_by(code1) %>%
#   mutate(diff_RT = on_time_2.rt - first_RT_mean)
# 
# # Verify the updated dataset
# print(filtered_columns)
```

```{r, include = FALSE}
# Format image numbers to remove path
filtered_columns$base_image <- gsub("[^0-9]", "", filtered_columns$base_image)



# Only analyze trials with correct choices
filtered_cols_accurate <- filtered_columns %>% filter(choice_1 == correct_answer_1 & choice_2 == correct_answer_2)

unique_values <- unique(filtered_cols_accurate$target_condition)
print(unique_values)

filtered_columns <- filtered_columns %>% mutate(
  first_choice_wrong = ifelse(choice_1 != correct_answer_1, 1, 0),
  second_choice_wrong = ifelse(choice_2 != correct_answer_2, 1, 0))

second_choice_wrong <- filtered_columns %>% 
  filter(choice_2 != correct_answer_2 & choice_1 == correct_answer_1)
```

```{r, include = FALSE}

dt <- table(second_choice_wrong$target_condition)

# Convert table to dataframe
df <- as.data.frame(dt)

# # Sort the dataframe based on the Var1 column
df <- arrange(df, Var1)
```

```{r, include = FALSE}
print(colnames(filtered_cols_accurate))

# compute difference scores for each participant
diff_scores <- filtered_cols_accurate 
```

```{r, include = FALSE}
means <- filtered_cols_accurate %>% # filtered_cols_accurate
  dplyr::group_by(target_condition, image_condition) %>%
  dplyr::summarize(on_time_rt_mean = mean(as.numeric(on_time.rt)),
                   on_time_2_rt_mean = mean(as.numeric(on_time_2.rt)),
                   difference_mean = mean(as.numeric(difference_rt)))

```

```{r, include = FALSE}
# Melt the means dataframe to long format
means_long <- reshape2::melt(means, id.vars = c("target_condition", "image_condition"))
```

```{r}
# collapsed_diff_scores <- diff_scores %>%
#   group_by(condition) %>%
#   mutate(condition_combined = case_when(
#     condition %in% c("DD", "NN") ~ "DD_NN",
#     condition %in% c("ND", "DN") ~ "ND_DN",
#     condition %in% c("DI", "NI") ~ "DI_NI",
#     TRUE ~ as.character(condition)
#   )) %>%
#   group_by(condition_combined)
# 
# # compute mean difference scores by condition and participant
# collapsed_diff_scores_means <- collapsed_diff_scores %>% 
#   dplyr::group_by(condition_combined) %>% 
#   dplyr::summarise(mean_diff_score = mean(difference_rt))

```

```{r, include = FALSE}
# compute mean difference scores by condition and participant
diff_scores_means <- diff_scores %>% 
  dplyr::group_by(target_condition, image_condition) %>% 
  dplyr::summarise(mean_diff_score = mean(difference_rt))

# Summarize the data to compute percentage of values above and below 0 for each target_condition
summary_df <- diff_scores %>%
  group_by(target_condition, image_condition) %>%
  dplyr::summarize(n = n(),
                   above_0 = sum(difference_rt > 0),
                   below_0 = sum(difference_rt < 0)) %>%
  mutate(above_0_percent = paste0(round(above_0 / n * 100), "%"),
         below_0_percent = paste0(round(below_0 / n * 100), "%"))

# Reshape the data to long format for the label data.frame
label_df <- summary_df %>%
  pivot_longer(cols = c("above_0_percent", "below_0_percent"), names_to = "label_type", values_to = "label_txt") %>%
  mutate(label_type = ifelse(label_type == "above_0_percent", "Above 0", "Below 0"))

# Calculate the mean diff_score for each participant
# diff_scores_avg <- diff_scores %>%
#   group_by(participant, condition) %>%
#   dplyr::summarize(mean_diff_score = mean(diff_RT))
```

```{r}
# filtered_cols_accurate <- filtered_cols_accurate %>%
#   mutate(marcel_type = case_when(
#     code1 == code2 ~ "congruent",
#     code2 == "I" ~ "control",
#     TRUE ~ "incongruent"
#   ))
```

```{r, include = FALSE}
# two_by_three <- filtered_cols_accurate %>%
#   # separate(target_condition, into = c("code1", "code2"), sep = 1) %>% # split into two columns
#   filter(target_condition %in% c("D", "N")) %>%
#   group_by(image_condition) # group by columns starting with D or I
# 
# # Convert code1 and code2 to a factor variable
# two_by_three$code1 <- factor(two_by_three$code1)
# two_by_three$code2 <- factor(two_by_three$code2)
# 
# two_by_three %>% dplyr::summarise(mean_rt = mean(on_time_2.rt))  # calculate mean on_time.rt for each group
# two_by_three$rt_gm <- mean(two_by_three$on_time_2.rt)
```


```{r, include = FALSE}
# # merge the two data frames
# merged_df <- two_by_three
#   
#   # merge(two_by_three, reshape, by = "participant", all = TRUE)

```

```{r, include = FALSE}
# merged_df$code1 <- relevel(merged_df$code1, ref = "N")
# merged_df$code2 <- relevel(merged_df$code2, ref = "I")
# 
# summary_df <- plyr::ddply(merged_df, c("code1", "code2"),
#                           summarize, mean_rt = mean(on_time_2.rt),
#                           se_rt = sd(on_time_2.rt) / sqrt(length(on_time_2.rt)))

```



# Exploratory data analysis

```{r, echo = FALSE}
# count number of distinct participants
num_participants <- length(unique(data$participant))

# print result
cat("Number of participants:", num_participants)
```

```{r}
# Create the scatter plot
ggplot(filtered_cols_accurate, aes(x = on_time.rt, y = on_time_2.rt, color = target_condition)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Response to Word 1", y = "Response to Word 2") +
  theme_minimal()

cor.test(filtered_cols_accurate$on_time.rt, filtered_cols_accurate$on_time_2.rt)
```

First, I want to gain a sense of the distribution of responses to both the priming word (histogram 1) and target word (histogram 2.)

```{r, echo = FALSE}
# Histogram of on_time.keys (reaction time to first word)
ggplot(filtered_columns, aes(x = on_time.rt)) +
  geom_histogram(binwidth = 0.01) +
  labs(
    title = "Distribution for first key press (without cutoffs)", 
    x = "RTs", 
    y = "Frequency")

# Histogram of on_time_2.keys (reaction time to second word)
ggplot(filtered_columns, aes(x = on_time_2.rt)) +
  geom_histogram(binwidth = 0.01) +
  labs(
    title = "Distribution for second key press (without cutoffs)", 
    x = "RTs", 
    y = "Frequency")

# Histogram of on_time.keys (reaction time to first word)
ggplot(filtered_cols_accurate, aes(x = on_time.rt)) +
  geom_histogram(binwidth = 0.01) +
  labs(
    title = "Distribution for first key press (without cutoffs)", 
    x = "RTs", 
    y = "Frequency")

# Histogram of on_time_2.keys (reaction time to second word)
ggplot(filtered_cols_accurate, aes(x = on_time_2.rt)) +
  geom_histogram(binwidth = 0.01) +
  labs(
    title = "Distribution for second key press (without cutoffs)", 
    x = "RTs", 
    y = "Frequency")


```

The data have a slight skew, although transforming them could remove variance of interest.

Now, let's take a look at the means by condition, bearing in mind that trials ending in "I" are slowed down about 30msec due to "yes" bias -- i.e., participants are slower to respond "no" to irrelevant words than they are to respond "yes" to relevant words.

```{r, echo = FALSE}
print(means)
```

```{r}
means %>%
  ggplot(aes(x = target_condition, y = on_time_2_rt_mean, fill = image_condition)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("Target Condition")
```
```{r, echo = FALSE, warning = FALSE}
# ggplot(filtered_columns, aes(x = NR_composite)) +
#   labs(title = "Distribution of NR composite scores", x = "RTs", y = "Frequency") +
#   geom_histogram(fill="#69b3a2", color="#e9ecef")
```



# Pairwise comparisons

Controlling for multiple comparisons using a Bonferroni correction, it looks like both incongruent (DN and ND) and irrelevant (ID and IN) trials are significantly different from congruent trials (DD and NN), but incongruent and irrelevant trials do not differ significantly from each other.



# 2x3 interaction dummy coding

Regardless of whether we use dummy or simple coding, we find significant interaction effects, providing support for our hypotheses. That is, reaction times vary as a function of the interaction between a given construal (the priming word) and whether another construal (the target word) is congruent with or in conflict with that construal.



```{r, echo = FALSE}
one_by_three <- filtered_columns %>% filter(target_condition %in% c("D", "I", "N"))

one_by_three$target_condition <- as.factor(one_by_three$target_condition)
one_by_three$target_condition <- relevel(one_by_three$target_condition, ref = "I")

two_by_three <- one_by_three %>% filter(image_condition == "exper")

# Adjust the options for the summary output
options(digits = 4)
options(pillar.sigfig = 6)

# Fit the linear mixed-effects model
one_by_three_model <- lmer(on_time_2.rt ~ target_condition * image_condition + (1 | participant), data = one_by_three, REML = TRUE)
summary(one_by_three_model)


# Fit the linear mixed-effects model
two_by_three_model <- lmer(on_time_2.rt ~ target_condition + (1 | participant), data = two_by_three, REML = TRUE)
summary(two_by_three_model)

# Fit the linear mixed-effects model
# two_by_three_model <- lmer(on_time_2.rt ~ run_num + code1 * code2 + (1 | participant), data = two_by_three, REML = TRUE)
# 
# two_by_three_early_runs <- two_by_three %>% filter(run_num %in% c(1, 2, 3, 4))
# 
# two_by_three$run_num <- as.factor(two_by_three$run_num)
# two_by_three$run_num <- relevel(two_by_three$run_num, ref = "5")
# two_by_three_model <- lmer(on_time_2.rt ~ run_num + code1 * code2 + (1 | participant), data = two_by_three, REML = TRUE)
# 
# 
# # Display the summary output with p-values
# summary(two_by_three_model)
```


```{r}
# two_by_three %>%
#   group_by(image_condition, marcel_type) %>%
#   summarize(mean_on_time_2_rt = mean(on_time_2.rt, na.rm = TRUE))
# 
# # Set "control" as the reference level
# two_by_three$marcel_type <- as.factor(two_by_three$marcel_type)
# two_by_three$marcel_type <- relevel(two_by_three$marcel_type, ref = "control")
# 
# head(two_by_three)
# 
# # Fit the linear mixed-effects model
# t1_model <- 
#   lmer(on_time_2.rt ~ marcel_type * image_condition + (1 | participant), 
#        data = two_by_three, 
#        REML = TRUE
#        )
# 
# summary(t1_model)
```


```{r}
# marcel_data <- filtered_cols_accurate %>%
#   filter(code1 %in% c("D", "N")) %>%
#   mutate(marcel_type = relevel(factor(marcel_type), ref = "control"))
# 
# 
# marcel_model <- lmer(
#   on_time_2.rt ~ code1 * marcel_type + (1 | participant), 
#   data = marcel_data, 
#   REML = TRUE)
# summary(marcel_model)


```



# 2x3 interaction simple coding

```{r}
# ########### custom coding ################
# # Change the order of levels
# marcel_data$code1 <- factor(marcel_data$code1, levels = c("D", "N"))
# marcel_data$marcel_type <- factor(marcel_data$marcel_type, levels = c("congruent", "control", "incongruent"))
# 
# 
# code1_contrast <- c(1, -1)
# marcel_type_contrast <- c(1, 0, -1)
# mat1 <- cbind(code1_contrast)
# mat1
# rownames(mat1) <- NULL
# colnames(mat1) <- NULL
# contrasts(marcel_data$code1) <- mat1
# mat2 <- cbind(marcel_type_contrast)
# mat2
# rownames(mat2) <- NULL
# colnames(mat2) <- NULL
# contrasts(marcel_data$marcel_type) <- mat2
# 
# marcel_model <- lmer(
#   on_time_2.rt ~ code1 * marcel_type + (1 | participant), 
#   data = marcel_data, 
#   REML = TRUE)
# summary(marcel_model)
```

```{r, echo = FALSE}
# two_by_three$code1 <- relevel(two_by_three$code1, ref = "D")
# two_by_three$code2 <- relevel(two_by_three$code2, ref = "I")
# 
# ########### custom coding ################
# code1_contrast <- c(1, -1)
# code2_contrast <- c(1, 0, -1)
# mat1 <- cbind(code1_contrast)
# mat1
# rownames(mat1) <- NULL
# colnames(mat1) <- NULL
# contrasts(two_by_three$code1) <- mat1
# mat2 <- cbind(code2_contrast)
# mat2
# rownames(mat2) <- NULL
# colnames(mat2) <- NULL
# contrasts(two_by_three$code2) <- mat2
# 
# two_by_three_model <- lmer(on_time_2.rt ~ code1 * code2 + NR_composite + (1|participant), data=two_by_three)
# 
# # Print the summary of the model to see the results
# summary(two_by_three_model)
```

# Naive realism plot

```{r}
# DD_vs_NN <- filtered_cols_accurate %>%
#   filter(condition %in% c("DD", "NN"))
# 
# cor.test(DD_vs_NN$NR_composite, DD_vs_NN$on_time_2.rt)
```

```{r}
# # Create scatter plot
# filtered_cols_accurate <- filtered_cols_accurate %>% filter(condition %in% new_order)
# # cor.test(DN_vs_ND$NR_composite, DN_vs_ND$on_time_2.rt)
# cor.test(filtered_cols_accurate$NR_composite, filtered_cols_accurate$on_time_2.rt)
# 
# 
# # NR_model <- lmer(on_time_2.rt ~ code1 * code2 + (1|participant), data = DN_vs_ND) #  + NR_composite
# # 
# # summary(NR_model)
# # 
# # nr_plot1 <- ggplot(DN_vs_ND, aes(NR_composite, on_time_2.rt, color = "blue")) +
# #   geom_point() +
# #   geom_smooth(method = "lm", se = FALSE, color = "black") +
# #   labs(
# #     title = "Incongruent Trials Only",
# #     x = "Trait Naive Realism", 
# #     y = "Reaction time (sec)",
# #     caption = "R = 0.07296, p = 0.006" 
# #   ) +
# #   theme_minimal() +
# #   theme(legend.position="none") +
# #   geom_text(x = 11.5, y = .8, label = "**", size = 8, color = "black")
# # nr_plot1
# # 
# # nr_plot2 <- ggplot(filtered_cols_accurate, aes(NR_composite, on_time_2.rt, color = "blue")) +
# #   geom_point() +
# #   geom_smooth(method = "lm", se = FALSE, color = "black") +
# #   labs(
# #     title = "All Trial Types",
# #     x = "Trait Naive Realism", 
# #     y = "Reaction time (sec)",
# #     caption = "R = 0.09777, p < 0.001" 
# #   ) +
# #   theme_minimal() +
# #   theme(legend.position="none") +
# #   geom_text(x = 11.5, y = .8, label = "***", size = 8, color = "black")
# # nr_plot2
# 
# nr_plot2 <- ggplot(filtered_cols_accurate, aes(NR_composite, on_time_2.rt, color = condition)) +
#   geom_point() +
#   geom_smooth(method = "lm", se = FALSE, aes(color = condition)) +
#   labs(
#     title = "All Trial Types",
#     x = "Trait Naive Realism", 
#     y = "Reaction time (sec)",
#     caption = "R = 0.09527, p < 0.001" 
#   ) +
#   theme_minimal() +
#   geom_text(x = 11.5, y = .8, label = "***", size = 8, color = "black")
# nr_plot2
# 
# 
# # Save the ggplot as a PNG file
# # ggsave("naive_realism_plot.png", nr_plot1, width = 6, height = 4, dpi = 300)
# # ggsave("naive_realism_plot2.png", nr_plot2, width = 6, height = 4, dpi = 300)

```



# Interaction visualization

```{r, echo = FALSE}
# # Reorder the levels of the factor variables
# merged_df$code1 <- factor(merged_df$code1, levels = c("D", "N"))
# merged_df$code2 <- factor(merged_df$code2, levels = c("D", "I", "N"))
# 
# summary_df <- plyr::ddply(merged_df, c("code1", "code2", "run_num"),
#                           summarize, mean_rt = mean(on_time_2.rt),
#                           se_rt = sd(on_time_2.rt) / sqrt(length(on_time_2.rt)))
# 
# summary_df <-summary_df %>% filter(code2 %in% c("D", "I", "N"))
# 
# # Add a new column with custom labels
# summary_df$custom_labels <- c("congruent", "control", "incongruent", "incongruent", "control", "congruent")

```

```{r}
# summary_4runs <- diff_scores %>%
#   group_by(condition) %>%
#   filter(run_num %in% c(1, 2, 3, 4)) %>%
#   dplyr::summarize(n = n(),
#                    above_0 = sum(difference_rt > 0),
#                    below_0 = sum(difference_rt < 0)) %>%
#   mutate(above_0_percent = paste0(round(above_0 / n * 100), "%"),
#          below_0_percent = paste0(round(below_0 / n * 100), "%"))
# 
# # Reshape the data to long format for the label data.frame
# label_4runs <- summary_4runs %>%
#   pivot_longer(cols = c("above_0_percent", "below_0_percent"), names_to = "label_type", values_to = "label_txt") %>%
#   mutate(label_type = ifelse(label_type == "above_0_percent", "Above 0", "Below 0"))
# 
# merged_4runs <- merged_df %>% filter(run_num %in% c(1, 2, 3, 4))
# 
# summary_4runs <- plyr::ddply(merged_4runs, c("code1", "code2", "run_num"),
#                           summarize, mean_rt = mean(on_time_2.rt),
#                           se_rt = sd(on_time_2.rt) / sqrt(length(on_time_2.rt)))
# 
# summary_4runs <-summary_4runs %>% filter(code2 %in% c("D", "I", "N"))
# 
# # Add a new column with custom labels
# summary_4runs$custom_labels <- c("congruent", "control", "incongruent", "incongruent", "control", "congruent")
```


```{r}
# # Initial summary calculation
# summary_4runs <- diff_scores %>%
#   group_by(condition, image_condition) %>%
#   # filter(run_num %in% c(1, 2, 3, 4)) %>%
#   dplyr::summarize(n = n(),
#                    above_0 = sum(difference_rt > 0),
#                    below_0 = sum(difference_rt < 0)) %>%
#   mutate(above_0_percent = paste0(round(above_0 / n * 100), "%"),
#          below_0_percent = paste0(round(below_0 / n * 100), "%"))
# 
# # Reshape data for label dataframe
# label_4runs <- summary_4runs %>%
#   pivot_longer(cols = c("above_0_percent", "below_0_percent"), names_to = "label_type", values_to = "label_txt") %>%
#   mutate(label_type = ifelse(label_type == "above_0_percent", "Above 0", "Below 0"))
# 
# # Filter merged_df for runs 1-4
# merged_4runs <- merged_df
# # %>% filter(run_num %in% c(1, 2, 3, 4))
# 
# # Summarize mean_rt and se_rt across all of runs 1-4, not per run
# summary_4runs <- plyr::ddply(merged_4runs, c("code1", "code2", "image_condition"),
#                        summarize, 
#                        mean_rt = mean(on_time_2.rt),
#                        se_rt = sd(on_time_2.rt) / sqrt(length(on_time_2.rt)))
# 
# 
# # 
# # summary_4runs <- plyr::ddply(merged_4runs, c("code1", "code2"),
# #                              summarize, mean_rt = mean(on_time_2.rt),
# #                              se_rt = sd(on_time_2.rt) / sqrt(length(on_time_2.rt)))
# 
# # Further filter the summary dataframe
# summary_4runs <- summary_4runs %>% filter(code2 %in% c("D", "I", "N"))
# 


```


```{r}
# real_words_only <- summary_4runs %>%
#   filter(code2 != "c")
# 
# real_words_only$code2 <- factor(real_words_only$code2, levels = c("D", "I", "N"))
# 
# length(real_words_only$custom_labels)
# nrow(real_words_only)
# 
# # Add custom labels column
# # real_words_only$custom_labels <- c("congruent", "congruent", "control", "control", "incongruent", "incongruent", "incongruent", "incongruent", "control",  "control", "congruent", "congruent")
# 
# # Plot the data with error bars
# plot1a <- ggplot(real_words_only, aes(x = code1, y = mean_rt, fill = code2)) +
#   geom_bar(stat = "identity", position = "dodge") +
#   geom_errorbar(
#     aes(ymin = mean_rt - se_rt,
#         ymax = mean_rt + se_rt),
#     width = 0.2,
#     position = position_dodge(0.9)) +
#   labs(
#     x = "First Word", 
#     y = "Reaction time (sec)") +
#   scale_fill_manual(
#     name = "Second Word", 
#     # labels = c("Dominant", "Irrelevant", "Nondominant"),
#     values = wes_palette("GrandBudapest1")) +
#   theme_minimal() +
#   # scale_x_discrete(labels = c("Dominant", "Nondominant")) +
#   coord_cartesian(ylim = c(.2, .9)) +
#   facet_wrap(~image_condition)
# 
# # plot1a <- plot1a + geom_text(
# #   aes(label = custom_labels),
# #   position = position_dodge(width = 0.9),
# #   angle = 90,     # Set the angle to 90 for vertical labels
# #   hjust = 1.3,    # Adjust horizontal justification
# #   color = "white",
# #   size = 4
# # ) +
# #   annotate("text", x = 0.5, y = .23, label = "↓", size = 7, vjust = 1)
#   
# 
# plot1a
```




```{r}
# # Initial summary calculation
# collapsed_conditions <- diff_scores %>%
#   group_by(condition) %>%
#   dplyr::summarize(n = n(),
#                    above_0 = sum(difference_rt > 0),
#                    below_0 = sum(difference_rt < 0)) %>%
#   mutate(above_0_percent = paste0(round(above_0 / n * 100), "%"),
#          below_0_percent = paste0(round(below_0 / n * 100), "%"))
# 
# # Reshape data for label dataframe
# collapsed_conditions_labels <- collapsed_conditions %>%
#   pivot_longer(cols = c("above_0_percent", "below_0_percent"), names_to = "label_type", values_to = "label_txt") %>%
#   mutate(label_type = ifelse(label_type == "above_0_percent", "Above 0", "Below 0"))
# 
# # Filter merged_df for runs 1-4
# merged_collapsed_conditions <- merged_df
# 
# # Summarize mean_rt and se_rt across all of runs 1-4, not per run
# collapsed_conditions <- plyr::ddply(merged_collapsed_conditions, c("code1", "code2"),
#                        summarize, 
#                        mean_rt = mean(on_time_2.rt),
#                        se_rt = sd(on_time_2.rt) / sqrt(length(on_time_2.rt)))
# 
# # Further filter the summary dataframe
# collapsed_conditions <- collapsed_conditions %>% filter(code2 %in% c("D", "I", "N"))

```

```{r}
# collapsed_conditions_real_words <- collapsed_conditions %>%
#   filter(code2 != "c")
# 
# collapsed_conditions_real_words$code2 <- factor(collapsed_conditions_real_words$code2, levels = c("D", "I", "N"))
# 
# length(collapsed_conditions_real_words$collapsed_conditions_labels)
# nrow(collapsed_conditions_real_words)
# 
# # # Add custom labels column
# collapsed_conditions_real_words$custom_labels <- c("congruent", "control", "incongruent", "incongruent", "control", "congruent")
# 
# # Plot the data with error bars
# plot1a <- ggplot(collapsed_conditions_real_words, aes(x = code1, y = mean_rt, fill = code2)) +
#   geom_bar(stat = "identity", position = "dodge") +
#   geom_errorbar(
#     aes(ymin = mean_rt - se_rt,
#         ymax = mean_rt + se_rt),
#     width = 0.2,
#     position = position_dodge(0.9)) +
#   labs(
#     x = "First Word", 
#     y = "Reaction time (sec)") +
#   scale_fill_manual(
#     name = "Second Word", 
#     # labels = c("Dominant", "Irrelevant", "Nondominant"),
#     values = wes_palette("GrandBudapest1")) +
#   theme_minimal() +
#   # scale_x_discrete(labels = c("Dominant", "Nondominant")) +
#   coord_cartesian(ylim = c(.2, .7))
# 
# # plot1a <- plot1a + geom_text(
# #   aes(label = custom_labels),
# #   position = position_dodge(width = 0.9),
# #   angle = 90,     # Set the angle to 90 for vertical labels
# #   hjust = 1.3,    # Adjust horizontal justification
# #   color = "white",
# #   size = 4
# # ) +
# #   annotate("text", x = 0.5, y = .23, label = "↓", size = 7, vjust = 1)
# #   
# 
# plot1a
```





```{r}
# # Add the new column based on conditions
# merged_4runs <- merged_4runs %>%
#   mutate(congruency = case_when(
#     as.character(code1) == as.character(code2) ~ "congruent",
#     code2 == "I" ~ "control",
#     TRUE ~ "incongruent"
#   ))
# 
# 
# # Summarize mean_rt and se_rt based on the new column
# summary_by_congruency <- merged_4runs %>%
#   group_by(congruency, image_condition) %>%
#   summarize(
#     mean_rt = mean(on_time_2.rt),
#     se_rt = sd(on_time_2.rt) / sqrt(n())
#   )

```

```{r}
# anova_result <- aov(on_time_2.rt ~ congruency, data = merged_4runs)
# summary(anova_result)
# 
# library(emmeans)
# pairwise_comparisons <- emmeans(anova_result, pairwise ~ congruency, adjust = "tukey")
# pairwise_comparisons
# 
# # Convert congruency to a factor
# merged_4runs$congruency <- as.factor(merged_4runs$congruency)
# 
# # Set "control" as the reference level
# merged_4runs$congruency <- relevel(merged_4runs$congruency, ref = "control")
# 
# # Now fit the linear regression model
# model <- lm(on_time_2.rt ~ congruency, data = merged_4runs)
# summary(model)


```


```{r}
# plot1 <- ggplot(summary_by_congruency, aes(x = congruency, fill = congruency, y = mean_rt)) +
#   geom_bar(stat = "identity", width = 0.7) +
#   geom_errorbar(
#     aes(ymin = mean_rt - se_rt, 
#         ymax = mean_rt + se_rt),
#     width = 0.2) +
#   labs(
#     x = "Word type", 
#     y = "Reaction time (sec)") +
#   theme_light() +
#   coord_cartesian(ylim = c(.2, 0.75)) +
#   scale_fill_manual(
#     values = wes_palette("GrandBudapest1")) +
#   theme(legend.position = "none",
#         axis.title.x = element_text(size = 14),  # Adjust size for x-axis label
#         axis.title.y = element_text(size = 14),  # Adjust size for y-axis label
#         axis.text.x = element_text(size = 12),   # Adjust size for x-axis tick labels
#         axis.text.y = element_text(size = 12)) + # Adjust size for y-axis tick labels
#   facet_wrap(~image_condition)
#   
# 
# plot1



```



```{r}
# plot1 <- ggplot(summary_by_congruency, aes(x = congruency, y = mean_rt)) +
#   geom_bar(stat = "identity", fill = "#FFA07A", width = 0.7) +
#   geom_errorbar(
#     aes(ymin = mean_rt - se_rt, 
#         ymax = mean_rt + se_rt),
#     width = 0.2) +
#   labs(
#     x = "Word type", 
#     y = "Reaction time (sec)") +
#   theme_light() +
#   coord_cartesian(ylim = c(.2, .8)) +
#   theme(legend.position = "none",
#         axis.title.x = element_text(size = 14),  # Adjust size for x-axis label
#         axis.title.y = element_text(size = 14),  # Adjust size for y-axis label
#         axis.text.x = element_text(size = 12),   # Adjust size for x-axis tick labels
#         axis.text.y = element_text(size = 12))   # Adjust size for y-axis tick labels
# 
# plot1



```




```{r}
# # Plot the data with error bars
# plot1 <- ggplot(summary_df, aes(x = code1, y = mean_rt, fill = code2)) +
#   geom_bar(stat = "identity", position = "dodge") +
#   geom_errorbar(
#     aes(ymin = mean_rt - se_rt, 
#         ymax = mean_rt + se_rt),
#     width = 0.2, 
#     position = position_dodge(0.9)) +
#   labs(
#     x = "First Word", 
#     y = "Reaction time (sec)") +
#   scale_fill_manual(
#     name = "Second Word", 
#     labels = c("Dominant", "Irrelevant", "Nondominant"),
#     values = wes_palette("GrandBudapest1")) +
#   theme_minimal() +
#   # geom_text(x = 1.5, y = 1.1, label = "***", size = 10, color = "black") +
#   scale_x_discrete(labels = c("Dominant", "Nondominant")) +
#   coord_cartesian(ylim = c(.2, .8)) + facet_grid(. ~ run_num)
# 
# plot1
```


```{r}
# 
# # Add geom_text() to insert custom labels with vertical orientation
# plot1 <- plot1 + geom_text(
#   aes(label = custom_labels),
#   position = position_dodge(width = 0.9),
#   angle = 90,     # Set the angle to 90 for vertical labels
#   hjust = 1.3,    # Adjust horizontal justification
#   color = "white",
#   size = 4
# ) +
#   annotate("text", x = 0.5, y = .23, label = "↓", size = 7, vjust = 1)
#   
# print(plot1)
```


```{r}
# # Calculate the positions for the significance bars
# bar_width <- 0.35  # Adjust this value as per your preference
# bar_positions <- c(.75, 1.5)
# significance_df <- data.frame(
#   xstart = c(.7, 1.7, .6),
#   xend = c(1.3, 2.25, 2.32),
#   y = c(0.9, 0.9, 1.05),
#   significance = c("***", "***", "")
# )
# 
# # Add the significance bars to the plot
# plot1 <- plot1 +
#   geom_segment(
#     data = significance_df,
#     aes(x = xstart, xend = xend, y = y, yend = y, fill = NA),
#     size = 1,
#     color = "black",
#     linetype = c("solid", "solid", "twodash")
#   ) +
#   geom_text(
#     data = significance_df,
#     aes(x = (xstart + xend) / 2, y = y + 0.025, label = significance, fill = NA),
#     size = 6,
#     color = "black",
#     vjust = 0
#   )

```

```{r}
# # Save the ggplot as a PNG file
# ggsave("interaction_plot_1.png", plot1, width = 6, height = 4, dpi = 300)
```

# Mistakes model


```{r}
# DN_primes <- filtered_columns %>% filter(code1 %in% c("D", "N"))
# 
# 
# # mistakes_model <- lm(second_choice_wrong ~ code1 * code2, data = DN_vs_ND)
# # 
# # # Display the summary output with p-values
# # summary(mistakes_model)
```

```{r}

first_choice_right <- filtered_columns %>% filter(first_choice_wrong == 0)

mistakes_model <- lm(second_choice_wrong ~ target_condition * image_condition, data = first_choice_right)

# Display the summary output with p-values
summary(mistakes_model)
# 
# first_choice_right_incong <- first_choice_right %>%
#   filter(condition %in% c("DN", "ND", "DI", "NI"))
# 
# first_choice_right_cong <- first_choice_right %>%
#   filter(condition %in% c("DD", "NN", "DI", "NI"))
# 
# first_choice_right_incong <- first_choice_right_incong %>%
#   mutate(category = ifelse(code2 == "I", "irrelevant", "incongruent"))
# 
# first_choice_right_cong <- first_choice_right_cong %>%
#   mutate(category = ifelse(code2 == "I", "irrelevant", "congruent"))

# mistakes_model <- lm(second_choice_wrong ~ code1 * category, data = first_choice_right_incong)
# summary(mistakes_model)
# 
# mistakes_model <- lm(second_choice_wrong ~ code1 * category, data = first_choice_right_cong)
# summary(mistakes_model)

```

# Mistakes plots

```{r, echo = FALSE}
# second_choice_wrong$target_ <- factor(second_choice_wrong$condition, levels = new_order)
# 
# dt <- table(second_choice_wrong$condition)

# Convert table to dataframe

mistakes_summary <- second_choice_wrong %>%
  filter(target_condition %in% c("D", "I", "N"))

# mistakes_summary <- mistakes_summary %>%
#   # separate(condition, into = c("code1", "code2"), sep = 1) %>% # split into two columns
#   filter(code1 %in% c("D", "N")) %>%
#   group_by(code1, code2) # group by columns starting with D or I

mistakes_summary <- mistakes_summary %>%
  dplyr::group_by(target_condition, image_condition) %>%
  dplyr::summarise(Freq = n())
```



```{r}
# # Step 1: Create a new column to represent the condition you want to calculate proportions for
# filtered_columns$condition <- as.factor(filtered_columns$condition)

# Step 2: Calculate the proportions and confidence intervals separately for each value of "condition"
results <- filtered_columns %>%
  group_by(target_condition, image_condition) %>%
  summarise(count_condition = sum(choice_2 != correct_answer_2 & choice_1 == correct_answer_1),
            count_choice_1_condition = sum(choice_1 == correct_answer_1)) %>%
  rowwise() %>%
  do({
    proportion <- .$count_condition / .$count_choice_1_condition
    ci <- binom.test(x = .$count_condition, n = .$count_choice_1_condition)$conf.int
    data.frame(., proportion = proportion, ci_lower = ci[1], ci_upper = ci[2])
  }) %>%
  ungroup()

# Add significance bars
results <- results %>%
  mutate(significance_bar = ifelse(proportion > ci_upper, "*", ifelse(proportion < ci_lower, "**", "")))

results$proportion <- results$proportion * 100
results$ci_upper <- results$ci_upper * 100
results$ci_lower <- results$ci_lower * 100

# Print the results
print(results)

# This updated code should calculate the proportions, confidence intervals, and add significance bars for count data for each condition individually.

```


```{r, echo = FALSE}
# results$condition <- factor(results$condition, levels = my_order)

# results <- results %>%
#   separate(condition, into = c("code1", "code2"), sep = 1)

# results <- results %>%
#   filter(code1 %in% c("D", "N"))

add_custom_labels <- function(results) {
  results$custom_labels <- ifelse(results$code2 == "I", "irrelevant",
                                  ifelse(results$code1 == results$code2, "con.", "incongruent"))
  return(results)
}

# Assuming 'results' is your dataframe
results <- add_custom_labels(results)

# Create bar chart
mistakes_plot <- 
  results %>%
  filter(target_condition %in% c("D", "N", "I")) %>%
           ggplot(aes(x = target_condition, y = proportion, fill = image_condition)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(x = "Target Word", y = "% Mistakes after 1st Choice Correct") +
  scale_fill_manual(
    # name = "Second Word", 
    # labels = c("Dominant", "Irrelevant", "Nondominant"),
    values = wes_palette("GrandBudapest1")) +
  theme_minimal() +
  geom_errorbar(
    aes(ymin = ci_lower, ymax = ci_upper), 
    width = 0.2, 
    position = position_dodge(0.9)) +
    # scale_x_discrete(labels = c("Dominant", "Nondominant")) +
    coord_cartesian(ylim = c(0, 15)) +
    facet_wrap(~image_condition)

mistakes_plot

# Add geom_text() to insert custom labels with vertical orientation
mistakes_plot <- mistakes_plot + geom_text(
  aes(label = custom_labels),
  position = position_dodge(width = 0.9),
  angle = 90,     # Set the angle to 90 for vertical labels
  hjust = 1.5,    # Adjust horizontal justification
  color = "white",
  size = 4
)

print(mistakes_plot)

# This seems like a ceiling effect -- i.e. people perform pretty accurately in general. It's interesting that irrelevant trials are slower though -- maybe due to the different integration process (lack of conscious thinking about meaning) the inhibition of meaning of incongruent trials isn't as great

```

```{r}
# two_by_three$code1 <- relevel(two_by_three$code1, ref = "N")
# two_by_three$code2 <- relevel(two_by_three$code2, ref = "I")

# Fit the linear mixed-effects model
two_by_three_model <- lmer(on_time_2.rt ~ code2 * image_condition + (1 | participant), data = two_by_three, REML = TRUE)

summary(two_by_three_model)
```

```{r, echo = FALSE}
# # Create bar chart
# mistakes_plot <- ggplot(mistakes_summary, aes(x = code1, y = Freq, fill = code2)) +
#   geom_bar(stat = "identity", position = "dodge") +
#   labs(x = "Prime Word", y = "Mistake Frequency") +
#   ggtitle("The meaning of alternative construals is inhibited") +
#   scale_fill_manual(name = "Response Word", values = wes_palette("GrandBudapest1")) +
#   theme_minimal()
# 
# mistakes_plot
# 
# Save the ggplot as a PNG file
ggsave("mistakes_plot.png", mistakes_plot, width = 6, height = 4, dpi = 300)
```


Finally, we find that participants are more likely to inaccurately respond that a word isn't a good descriptor of an image for incongruent trials -- further evidence that the meaning of words is being inhibited.

```{r, echo = FALSE}
# # Create the plot
# ggplot(sum_new, aes(x = condition, y = V1)) +
#   geom_bar(stat = "identity", position = position_dodge(width = 0.9)) +
#   labs(title = "First choice correct but second choice incorrect",
#        x = "Condition", y = "Proportion of incorrect responses") +
#   theme(panel.grid.major = element_blank(),
#         panel.grid.minor = element_blank(),
#         panel.border = element_blank(),
#         axis.line = element_line(size = 0.5),
#         axis.text = element_text(size = 8, family = "Helvetica"),
#         axis.title = element_text(size = 10, family = "Helvetica"),
#         plot.title = element_text(size = 12, family = "Helvetica", face = "bold"),
#         legend.position = "none") + 
#   theme_minimal() +
#   scale_fill_manual(values = wes_palette("GrandBudapest1")) 

# 
# # Save the ggplot as a PNG file
# ggsave("mistakes_plot.png", mistakes_plot, width = 6, height = 4, dpi = 300)
```
